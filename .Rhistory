<<<<<<< HEAD
close(ch)
}
#   ********
#   Retrieve basic data set, one line per fish or group of fish of same length.
catch.df   <- F.get.indiv.fish.data( site, taxon, run, min.date, max.date, keep="unmarked" )
site
nvisits <- F.buildReportCriteria( site, min.date, max.date )
db.file
river
river <- "Mokelumne River"
=======
sp.string <- paste( sp.string, ", ", dts, sep="")
title( main=sp.string, line=1, cex.main=1 )
title( main=disc, line=0, cex.main=0.75)
title( main=disc, line=0.25, cex.main=0.5)
title( main=disc, line=0.25, cex.main=0.75)
title( main=disc, line=0.25, cex.main=0.70)
dev.off()
#   ********
#   Now plot
#   Define plotting variables
# x <- catch.df$visitTime
# n <- catch.df$n
# lstage <- catch.df$lifeStageID
x <- catch.df$EndTime
y <- catch.df$forkLength
lstage <- catch.df$lifeStage
n <- catch.df$Unmarked
valid <- catch.df$includeCatchID
#   Drop record if any critical data is missing
#   If we are talking salmon here, limit the lifestages to fry, parr, and smolt
drop <- is.na(x) | is.na(y) | is.na(lstage) | is.na(n)
if( (length(taxon) == 1) & (taxon == 161980) ){
#     drop <- drop | (lstage > 8)
drop <- drop | !(lstage %in% c('Fry','Parr','Smolt'))
}
x <- x[!drop]
y <- y[!drop]
lstage <- lstage[!drop]
n <- n[!drop]
valid <- valid[!drop]
#   Convert from lifestages the traps used to life stages that CAMP uses.  The conversion is in table rst.life.stages
# JASON OBSOLETE -- QUERY THAT GETS CATCH WORKS ON DESCRIPTORS INSTEAD OF IDS -- 1/26/2015
# u.l.s <- sort(unique(lstage))
# for( l.s in u.l.s ){
#     camp.l.s <- rst.life.stage$lifeStageCAMPID[ rst.life.stage$lifeStageID == l.s ]
#     lstage[ lstage == l.s ] <- camp.l.s
# }
#   Rep the values for number of fish of that particular length
x <- rep(x, n)
y <- rep(y, n)
lstage <- rep(lstage, n)
valid <- rep(valid, n)
#   Main plot
plot( x, y, type="n", xlab="", ylab="", xaxt="n" )
title( xlab="Date", cex.lab=1.5)
title( ylab="Fork Length (mm)", cex.lab=1.5, line=2.5 )
dts <- pretty(x)
axis( side=1, at=dts, labels=format(dts, "%d%b%y") )
life.stages <- sort(unique( lstage ))
cat(paste("Lifestages plotted:", paste(life.stages, collapse=", "), "\n"))
if( length(life.stages) == 3 ){
mycol <- c("red", "orange", "blue")
} else {
mycol <- rainbow( length(life.stages) )
}
mypch <- rev(1:(0+length(life.stages)))
ans.pts <- NULL
for( l.s in life.stages ){
ind <- l.s == lstage
xx <- x[ind]
yy <- y[ind]
jitx <- rnorm(sum(ind), sd=60*60*3)
#jity <- rnorm(sum(ind), sd=diff(range(y))/100)
jity <- 0
validv <- ifelse(valid[ind]==1,'Fishing','NotFishing')
points( xx + jitx, yy + jity, col=mycol[ which(l.s == life.stages)], pch=mypch[ which(l.s == life.stages)] )
ans.pts <- rbind( ans.pts, data.frame(lifestage=l.s, date=xx, fork.length.mm=yy, date.jittered=xx+jitx, fork.length.mm.jittered=yy+jity, fishing.status=validv ))
}
ans.pts <- ans.pts[order(ans.pts$date, ans.pts$lifestage, ans.pts$date.jittered, ans.pts$fork.length.mm.jittered),]
#95, 108, 122, 151, 152, 155
#   Add quantile lines
xx <- as.numeric(x) # no longer a POSIXct
x.bs <- bs( xx, df=6 )
# jason add.  this can sometimes be singular, apparently.  leads to problems in finding an inverse.
rq.fit <- tryCatch(rq( y ~ x.bs, tau=c(0.05, 0.95) ), error = function(e) e)
xpred <- seq(quantile(xx,.01),quantile(xx,.99),length=200)
xp.bs <- bs( xpred, knots=attr(x.bs,"knots"), Boundary.knots=attr(x.bs,"Boundary.knots") )
if(rq.fit[1] == 'Singular design matrix'){
class(xpred) <- class(x)  # back to a POSIXct for output
#     ans.qr <- data.frame( date=xpred, q.05=ypred[,1], q.95=ypred[,2] )
} else {
ypred <- cbind(1,xp.bs)%*%coef(rq.fit)
lines( xpred, ypred[,1], col="black", lwd=3, lty=2 )
lines( xpred, ypred[,2], col="black", lwd=3, lty=2 )
class(xpred) <- class(x)  # back to a POSIXct for output
ans.qr <- data.frame( date=xpred, q.05=ypred[,1], q.95=ypred[,2] )
}
#   Main title
title( main=attr(catch.df, "site.name"), line=2, cex.main=2 )
sp.string <- attr(catch.df, "species.name")
if( !is.na(attr(catch.df, "runID")) ){
sp.string <- paste( sp.string, ", ", attr(catch.df, "run.name"), " run", sep="")
}
dts <- attr(catch.df, "run.season")
dts <- paste( format(dts$start, "%d%b%Y"), "to", format(dts$end, "%d%b%Y") )
sp.string <- paste( sp.string, ", ", dts, sep="")
title( main=sp.string, line=1, cex.main=1 )
title( main=disc, line=0.25, cex.main=0.70)
#
library(RODBC)
testing <- TRUE                   # points to different output folders.
platform <- 'CAMP_RST20151130'    # points to different platforms
paste(cat('testing == TRUE\n'))
setwd(paste0("\\\\LAR-FILE-SRV/Data/PSMFC_CampRST/ThePlatform/",platform,"/R-Interface/"))
source(paste0("\\\\LAR-FILE-SRV/Data/PSMFC_CampRST/ThePlatform/",platform,"/R-Interface/source_all_testing.R"))
theExcel <- read.csv('theExcel.csv')
theExcel <- theExcel[theExcel$Issues == '',]
rownames(theExcel) <- NULL
testi <- 1
>>>>>>> origin/master
by <- 'All'
river <- as.character(droplevels(theExcel[testi,]$streamName))
if(river == ''){
db.file <- db.file1
} else if(river == 'Sacramento River'){
db.file <- db.file2
} else if(river == 'American River'){
db.file <- db.file3
} else if(river == ''){
db.file <- db.file4
} else if(river == 'Feather River'){
db.file <- db.file5
} else if(river == 'Stanislaus River'){
db.file <- db.file6
} else if(river == 'Old American Test'){
db.file <- db.file7
} else if(river == 'Mokelumne River'){
db.file <- db.file8
#   } else if(river == "Knight's Landing"){
#     db.file <- db.file9
} else if(river == "Knight's Landing"){
db.file <- db.fileA
}
<<<<<<< HEAD
db.file
river
river <- "Mokelumne River"
if(river == ''){
db.file <- db.file1
} else if(river == 'Sacramento River'){
db.file <- db.file2
} else if(river == 'American River'){
db.file <- db.file3
} else if(river == ''){
db.file <- db.file4
} else if(river == 'Feather River'){
db.file <- db.file5
} else if(river == 'Stanislaus River'){
db.file <- db.file6
} else if(river == 'Old American Test'){
db.file <- db.file7
} else if(river == 'Mokelumne River'){
db.file <- db.file8
#   } else if(river == "Knight's Landing"){
#     db.file <- db.file9
} else if(river == "Knight's Landing"){
db.file <- db.fileA
}
db.file
F.length.frequency( site, taxon, run, min.date, max.date,     paste0(output.file,"_ls=F"),   by.lifestage=FALSE          )
=======
if(river != 'Old American Test'){
site         <- theExcel[testi,]$siteID
siteText     <- as.character(droplevels(theExcel[testi,]$Site))
run          <- theExcel[testi,]$RunID
runText      <- as.character(droplevels(theExcel[testi,]$SalmonRun))
min.date     <- as.character(as.Date(theExcel[testi,]$minvisitTime,format = "%m/%d/%Y"))
max.date     <- as.character(as.Date(theExcel[testi,]$maxvisitTime,format = "%m/%d/%Y"))
} else {
river        <- 'american'
site         <- 57000
siteText     <- 'testing'
run          <- 4
runText      <- 'Winter'
min.date     <- "2013-10-01"
max.date     <- "2014-09-29"
}
taxon        <- 161980
output.file  <- paste0("..//Outputs//",river,"//Run ",testi,"--",by,"_",river,"_",siteText,"_",min.date,"_",max.date)
ci           <- TRUE
output.type  <- "odt"
from         <- "Trent McDonald, Ph.D., WEST Incorporated"
to           <- "Doug Threloff, USFWS CAMP Coordinator"
return.addr  <- "FISH AND WILDLIFE SERVICE!USFWS Caswell State Park Office!1234 Abbey Rd.!Caswell, California  96080!(530) 527-3043, FAX (530) 529-0292"
#   for(byj in 1:4){
#
#     if(byj == 1){
#       by <- 'day'
#     } else if(byj == 2){
#       by <- 'week'
#     } else if(byj == 3){
#       by <- 'month'
#     } else if(byj == 4){
#       by <- 'year'
#     }
#
#     F.passage       ( site, taxon, run, min.date, max.date, by,        output.file,                ci                      )
#   }
#    F.run.passage     ( site, taxon,      min.date, max.date, by=by,     output.file=output.file,         ci=TRUE            )
#    F.lifestage.passage(site, taxon,      min.date, max.date,            output.file,                     ci=TRUE            )
# }
F.size.by.date    ( site, taxon, run, min.date, max.date,            output.file                                         )
F.length.frequency( site, taxon, run, min.date, max.date,     paste0(output.file,"_ls=F"),   by.lifestage=FALSE          )
F.length.frequency( site, taxon, run, min.date, max.date,     paste0(output.file,"_ls=T"),   by.lifestage=TRUE           )
F.length.frequency <- function( site, taxon, run, min.date, max.date, output.file, by.lifestage ){
#
#   Plot frequency distribution of lengths.
#
#   Input:
#   db = full path and name of the Access data base to retrieve data from
#   site = site ID of the place we want, trap locaton
#   taxon = taxon number (from luTaxon) to retrieve
#   run = run ID of fish we want to do estimates for.
#   by.lifestage = if TRUE, produce histograms by lifestage, otherwise, lump all fish.
#
#   Output:
#   A graph, in "file".
#
>>>>>>> origin/master
#  Open a graphics device
if( !is.na(output.file) ){
#   ---- Open PNG device
out.graphs <- paste(output.file, "_len_freq.png", sep="")
if(file.exists(out.graphs)){
file.remove(out.graphs)
}
tryCatch({png(file=out.graphs,width=7,height=7,units="in",res=600)}, error=function(x){png(file=out.graphs)})
}
if( by.lifestage ){
#   *******
#   Open ODBC channel and retrieve lifestage labels
ch <- odbcConnectAccess(db.file)
CAMP.life.stage <- sqlFetch(ch, table.names["CAMP.life.stages"])
rst.life.stage <- sqlFetch(ch, table.names["life.stages"])
close(ch)
}
#   ********
#   Retrieve basic data set, one line per fish or group of fish of same length.
catch.df   <- F.get.indiv.fish.data( site, taxon, run, min.date, max.date, keep="unmarked" )
#  Open a graphics device
if( !is.na(output.file) ){
#   ---- Open PNG device
out.graphs <- paste(output.file, "_len_freq.png", sep="")
if(file.exists(out.graphs)){
file.remove(out.graphs)
}
tryCatch({png(file=out.graphs,width=7,height=7,units="in",res=600)}, error=function(x){png(file=out.graphs)})
}
if( by.lifestage ){
#   *******
#   Open ODBC channel and retrieve lifestage labels
ch <- odbcConnectAccess(db.file)
CAMP.life.stage <- sqlFetch(ch, table.names["CAMP.life.stages"])
rst.life.stage <- sqlFetch(ch, table.names["life.stages"])
close(ch)
}
#   *******
#   Retrieve db file name and table names and any other constants
No.code <- get("No.code", pos=.GlobalEnv)
Yes.code <- get("Yes.code", pos=.GlobalEnv)
tables <- get( "table.names", env=.GlobalEnv )
db <- get( "db.file", env=.GlobalEnv )
#   *******
#   First, save the start and stop dates of the run.
#   Need these to determine visits.
#   Need these to filter visits.
strt.dt <- as.POSIXct( min.date, format="%Y-%m-%d" )
end.dt <- as.POSIXct( max.date, format="%Y-%m-%d" )
run.season <- data.frame( start=strt.dt, end=end.dt )
#   *******
#   Open ODBC channel
ch <- odbcConnectAccess(db)
#   *******
#   Retreive common names for the site
sites <- sqlQuery( ch, paste("SELECT siteName, siteAbbreviation, siteID, streamName FROM", tables["sites"],
"WHERE (siteID =", site, ")" ))
F.sql.error.check(sites)
site.stream <- as.character(sites$streamName)
site.abbr <- as.character(sites$siteAbbreviation)
site.name <- as.character(sites$siteName)
#   Fetch subsite names
subsite.names <- sqlQuery( ch, paste("SELECT subSiteID, subSiteName FROM", tables["subsites"],
"WHERE (siteID =", site, ")" ))
F.sql.error.check(subsite.names)
subsite.names$subSiteName <- as.character(subsite.names$subSiteName)
#   Fetch species name
sp.codes <- sqlQuery(ch, paste("SELECT taxonID, commonName FROM", tables["species.codes"]))
F.sql.error.check(sp.codes)
sp.commonName <- as.character(sp.codes$commonName[ sp.codes$taxonID %in% taxon ])
#   Fetch run name
runs <- sqlQuery(ch, paste( "SELECT run, runID FROM", tables["run.codes"] ))
F.sql.error.check(runs)
run.name <- as.character(runs$run[ runs$runID == run ])
cat( paste(site.name, site.abbr, site.stream,  sep=":") )
cat("\n")
cat( paste(sp.codes$taxonID[ sp.codes$taxonID %in% taxon ], sp.commonName, run.name, sep=":") )
cat("\n")
tmp.df <- F.get.catch.data( site, taxon, min.date, max.date  )
catch <- tmp.df$catch
# F.sql.error.check(catch)
# if( nrow(catch) == 0 ){
#     return(catch)
# }
if(nrow(catch) >= 20) {cat("First 20 catch records...\n"); print(catch[1:20,])} else {cat("Catch records...\n"); print(catch)}
cat(paste(nrow(catch), "total records in catch table.\n"))
#   *****
nvisits <- F.buildReportCriteria( site, min.date, max.date )
if( nvisits == 0 ){
warning("Your criteria returned no trapVisit table records.")
return()
}
#   *****
#   Open ODBC channel
db <- get( "db.file", env=.GlobalEnv )
ch <- odbcConnectAccess(db)
#   *****
#   This SQL file develops the hours fished and TempSamplingSummary table
F.run.sqlFile( ch, "QrySamplePeriod.sql", R.TAXON=taxon )
#   *****
#   This SQL generates times when the traps were not fishing
F.run.sqlFile( ch, "QryNotFishing.sql" )
#   *****
#   This SQL generates unmarked fish by run and life stage
F.run.sqlFile( ch, "QryUnmarkedByRunLifestage.sql", R.TAXON=taxon )
#   Now, fetch the result
catch <- sqlFetch( ch, "TempSumUnmarkedByTrap_Run_Final" )
theLongCatches <- catch[catch$SampleMinutes > fishingGapMinutes,c('SampleDate','StartTime','EndTime','SampleMinutes','TrapStatus','siteID','siteName','trapPositionID','TrapPosition')]      # fishingGapMinutes set in source file -- it's global.
nLongCatches <- nrow(theLongCatches)
nLongCatches
catch$oldtrapPositionID <- catch$trapPositionID
includecatchID <- sqlFetch(ch, "TempSamplingSummary")             # jason add to get variable includeCatchID
F.sql.error.check(catch)
close(ch)
<<<<<<< HEAD
nrow(catch)
nrow(nvisits)
nvisits
catch <- sqlFetch( ch, "TempSumUnmarkedByTrap_Run_Final" )
#   *****
nvisits <- F.buildReportCriteria( site, min.date, max.date )
if( nvisits == 0 ){
warning("Your criteria returned no trapVisit table records.")
return()
}
#   *****
#   Open ODBC channel
db <- get( "db.file", env=.GlobalEnv )
ch <- odbcConnectAccess(db)
#   *****
#   This SQL file develops the hours fished and TempSamplingSummary table
F.run.sqlFile( ch, "QrySamplePeriod.sql", R.TAXON=taxon )
#   *****
#   This SQL generates times when the traps were not fishing
F.run.sqlFile( ch, "QryNotFishing.sql" )
#   *****
#   This SQL generates unmarked fish by run and life stage
F.run.sqlFile( ch, "QryUnmarkedByRunLifestage.sql", R.TAXON=taxon )
#   Now, fetch the result
catch <- sqlFetch( ch, "TempSumUnmarkedByTrap_Run_Final" )
# add 3/8/2016 -- look for long gaps.
theLongCatches <- catch[catch$SampleMinutes > fishingGapMinutes,c('SampleDate','StartTime','EndTime','SampleMinutes','TrapStatus','siteID','siteName','trapPositionID','TrapPosition')]      # fishingGapMinutes set in source file -- it's global.
nLongCatches <- nrow(theLongCatches)
if(nLongCatches > 0){
warning("Long gaps were found in the data so the LongGapLoop series will be run.")
# SQL code to find the gaps, and modify trapPositionIDs accordingly.
F.run.sqlFile( ch, "QryFishingGaps.sql", R.FISHGAPMIN=fishingGapMinutes )
# get the updated results
catch2 <- sqlFetch( ch, "TempSumUnmarkedByTrap_Run_Final" )
catch <- catch2[catch2$SampleMinutes <= fishingGapMinutes,]   # this becomes the master catch df
} else {
# no long gaps to worry about.  so just keep going with the version of catch that we already
# pulled in from the mdb.
catch$oldtrapPositionID <- catch$trapPositionID    # these two are the same.  include for compatibility.
}
includecatchID <- sqlFetch(ch, "TempSamplingSummary")             # jason add to get variable includeCatchID
F.sql.error.check(catch)
close(ch)
catch
tmp.df <- F.get.catch.data( site, taxon, min.date, max.date  )
#   *****
nvisits <- F.buildReportCriteria( site, min.date, max.date )
if( nvisits == 0 ){
warning("Your criteria returned no trapVisit table records.")
return()
}
#   *****
#   Open ODBC channel
db <- get( "db.file", env=.GlobalEnv )
ch <- odbcConnectAccess(db)
#   *****
#   This SQL file develops the hours fished and TempSamplingSummary table
F.run.sqlFile( ch, "QrySamplePeriod.sql", R.TAXON=taxon )
#   *****
#   This SQL generates times when the traps were not fishing
F.run.sqlFile( ch, "QryNotFishing.sql" )
#   *****
#   This SQL generates unmarked fish by run and life stage
F.run.sqlFile( ch, "QryUnmarkedByRunLifestage.sql", R.TAXON=taxon )
#   Now, fetch the result
catch <- sqlFetch( ch, "TempSumUnmarkedByTrap_Run_Final" )
# add 3/8/2016 -- look for long gaps.
theLongCatches <- catch[catch$SampleMinutes > fishingGapMinutes,c('SampleDate','StartTime','EndTime','SampleMinutes','TrapStatus','siteID','siteName','trapPositionID','TrapPosition')]      # fishingGapMinutes set in source file -- it's global.
nLongCatches <- nrow(theLongCatches)
if(nLongCatches > 0){
warning("Long gaps were found in the data so the LongGapLoop series will be run.")
# SQL code to find the gaps, and modify trapPositionIDs accordingly.
F.run.sqlFile( ch, "QryFishingGaps.sql", R.FISHGAPMIN=fishingGapMinutes )
# get the updated results
catch2 <- sqlFetch( ch, "TempSumUnmarkedByTrap_Run_Final" )
catch <- catch2[catch2$SampleMinutes <= fishingGapMinutes,]   # this becomes the master catch df
} else {
# no long gaps to worry about.  so just keep going with the version of catch that we already
# pulled in from the mdb.
catch$oldtrapPositionID <- catch$trapPositionID    # these two are the same.  include for compatibility.
}
includecatchID <- sqlFetch(ch, "TempSamplingSummary")             # jason add to get variable includeCatchID
F.sql.error.check(catch)
close(ch)
if(nvisits > 0 & nrow(catch) == 0){
warning("Your criteria returned no catch records.  Check to make sure valid Fishing occurred within your date range.")
stop
}
#   ******************************************************************
#   Assign time zone (probably does not matter)
time.zone <- get( "time.zone", env=.GlobalEnv )
attr(catch$StartTime, "tzone") <- time.zone
attr(catch$EndTime, "tzone") <- time.zone
#  jason add all this get includeCatchID:  Assign time zone (definitely does matter -- otherwise it goes to MST)
time.zone <- get( "time.zone", env=.GlobalEnv )
# includecatchID$StartTime <- includecatchID$timeSampleStarted
includecatchID$EndTime <- includecatchID$timeSampleEnded
includecatchID$ProjID <- includecatchID$projectDescriptionID
includecatchID$timeSampleStarted <- includecatchID$timeSampleEnded <- includecatchID$projectDescriptionID <- includecatchID$trapVisitID <- includecatchID$sampleGearID <- NULL
# attr(includecatchID$StartTime, "tzone") <- time.zone
attr(includecatchID$EndTime, "tzone") <- time.zone
includecatchID <- includecatchID[,c('trapPositionID','EndTime','ProjID','includeCatchID')]
# sampleGearID ProjID trapPositionID trapVisitID
catch <- merge(catch,includecatchID,by=c('trapPositionID','EndTime','ProjID'),all.x=TRUE)
catch
visit.ind <- !duplicated( catch$trapVisitID ) | (catch$TrapStatus == "Not fishing")
visits <- catch[visit.ind,!(names(catch) %in% c("Unmarked", "FinalRun", "lifeStage", "forkLength", "RandomSelection"))]
#   ********************************************************************
#   Subset the catches to just positives.  Toss the 0 catches and non-fishing visits.
catch <- catch[ (catch$Unmarked > 0) & (catch$TrapStatus == "Fishing"), ]
# get summary counts of catch run vs. lifetstage for internal checking.
totalFish <<- sum(catch$Unmarked)
# jason adds the if here 1/12/2016, since for some reports, we could have 0 valid catch, but non-zero invalid catch.
# aggregate doesn't work on zero rows, thus requiring the if-clause.
if(nrow(catch) > 0){
totalRun <<- aggregate(catch$Unmarked, list(FinalRun=catch$FinalRun), FUN=sum)
totalLifeStage <<- aggregate(catch$Unmarked, list(LifeStage=catch$lifeStage), FUN=sum)
totalRunXLifeStage <<- aggregate(catch$Unmarked, list(LifeStage=catch$lifeStage,FinalRun=catch$FinalRun), FUN=sum)
}
catch$Unassd <- catch$lifeStage # jason add to ID the unassigned lifeStage -- necessary to separate measured vs caught.
#   ********************************************************************
catchSave <<- catch
nHalfCone <- nrow(catch[catch$halfConeID == 1,])
nHalfCone
F.expand.plus.counts( catch )
catch <- F.expand.plus.counts( catch )
catch$preUnmarked <- catch$Unmarked
catch$halfConeAssignedCatch <- 0
catch$halfConeUnassignedCatch <- 0
catch$assignedCatch   <- ifelse(catch$Unassd != 'Unassigned',catch$Unmarked - catch$halfConeAssignedCatch,0)
catch$unassignedCatch <- ifelse(catch$Unassd == 'Unassigned',catch$Unmarked - catch$halfConeUnassignedCatch,0)
catch$modUnassignedCatch <- catch$halfConeUnassignedCatch + catch$unassignedCatch
catch$modAssignedCatch <- catch$halfConeAssignedCatch + catch$assignedCatch
# data query where all are full catch -- just set the fancy variables to zero.
catch <- F.expand.plus.counts( catch )
catch$preUnmarked <- catch$Unmarked
if(nrow(catch) > 0){catch$halfConeAssignedCatch <- 0}
if(nrow(catch) > 0){catch$halfConeUnassignedCatch <- 0}
catch$assignedCatch   <- ifelse(catch$Unassd != 'Unassigned',catch$Unmarked - catch$halfConeAssignedCatch,0)
catch$unassignedCatch <- ifelse(catch$Unassd == 'Unassigned',catch$Unmarked - catch$halfConeUnassignedCatch,0)
catch$modUnassignedCatch <- catch$halfConeUnassignedCatch + catch$unassignedCatch
catch$modAssignedCatch <- catch$halfConeAssignedCatch + catch$assignedCatch
catch
#   Reassign factor levels because they may have changed.  I.e., we may have eliminated "Unassigned"
catch$FinalRun <- as.character( catch$FinalRun )
catch$lifeStage <- as.character( catch$lifeStage )
#catch$lifeStage <- as.character( catch$Unassd ) jason - possibly delete
#   ********************************************************************
#   Assign batch dates -- jason adds the ifs 1/16/2016 to allow zero row visits and catch dfs to pass through
if(nrow(visits) > 0){visits <- F.assign.batch.date( visits )}
if(nrow(catch) > 0){catch <- F.assign.batch.date( catch )}
catch
F.get.catch.data <- function( site, taxon, min.date, max.date ){
#
#   Fetch the catch data for a SINGLE TAXON from an Access data base. Do some initial
#   computations, like dates.
#
#   input:
#   db = full path and name of the Access data base to retrieve data from
#   tables = vector with named components containing names
#           of the table in db to pull values from
#   site = site ID of place we want to do estimates for.
#   taxon = the taxon number(s) (from luTaxon) to retrieve.  If a scalar, only
#       one taxon is retrieved.  If vector of taxon id's, the sum of all
#       taxons is retrieved.
#   run = the single run ID of the fish we want.  If run = NA, all records for the fish
#       will be pulled.
#   min.date = minimum date for data to include. This is a text string in the format %Y-%m-%d, or YYYY-MM-DD
#   max.date = maximum date for data to include.  Same format as min.date
#
#   To be included in the catch data, a record has to be from the site,
#   of the correct taxon, of the correct run, and between min and max dates.
#
#f.banner <- function( x ){
#    cat("\n")
#    cat(paste(rep("=",50), collapse=""));
#    cat(x);
#    cat(paste(rep("=",50), collapse=""));
#    cat("\n")
#}
#   *****
nvisits <- F.buildReportCriteria( site, min.date, max.date )
if( nvisits == 0 ){
warning("Your criteria returned no trapVisit table records.")
return()
=======
nvCatch <- nvCatch[ (nvCatch$Unmarked > 0), ]                         #  Subset the catches to just positives.  Toss the 0 catches.
if(nrow(nvCatch) > 0){
nvCatch$Unassd <- nvCatch$lifeStage                                   #  jason add to ID the unassigned lifeStage -- necessary to separate measured vs caught.
nvCatch2 <- F.expand.plus.counts( nvCatch )                           #  Expand the Plus counts
nvCatch2$includeCatchID <- 2                                          #  make this df match the catch.df
nvCatch3 <- F.assign.batch.date( nvCatch2 )                           #  clean up dates
nvCatch.df <- nvCatch3[,names(catch.df)]                              #  get both dfs lined up correctly
if(nrow(catch.df) > 0 & nrow(nvCatch.df) > 0){
catch.df <- rbind(catch.df,nvCatch.df)                                #  use a new catch.df with non-valid fishing included
attributes(catch.df) <- attributesSafe
disc <- 'Fork lengths include both valid and invalid trapping data.'
} else if(nrow(catch.df) == 0 & nrow(nvCatch.df) > 0){
catch.df <- nvCatch.df
# no attributes to bring in -- do it now
attr(catch.df, "siteID" ) <- site
attr(catch.df, "site.name") <- catch.df$siteName[1]
attr(catch.df, "subsites") <- unique(catch.df$trapPositionID)
disc <- 'Fork lengths include only invalid trapping data;  no valid data exists for selected criteria.'
} else if(nrow(catch.df) > 0 & nrow(nvCatch.df) == 0){
catch.df <- catch.df
attributes(catch.df) <- attributesSafe
disc <- 'Fork lengths include only valid trapping data;  no invalid data exists for selected criteria.'
} # nrow(catch.df) == 0 condition below will catch situation when no records ever found.
}
if(nrow(catch.df) == 0){
plot( c(0,1), c(0,1), xaxt="n", yaxt="n", type="n", xlab="", ylab="")
text( .5,.5, "All Zero's\nCheck dates\nCheck that finalRunID is assigned to >=1 fish per visit\nCheck sub-Site were operating between dates")
dev.off(dev.cur())
ans <- out.graphs
cat("FAILURE - F.length.frequency\n\n")
cat(paste("Working directory:", getwd(), "\n"))
cat(paste("R data frames saved in file:", "<no RData saved>", "\n\n"))
cat("Number of files created in working directory = 1\n")
cat(paste(out.graphs, "\n"))
cat("\n")
return(catch.df)
}
if(class(catch.df$lifeStage) == 'factor'){catch.df$lifeStage <- as.character(droplevels(catch.df$lifeStage))}   # jason add
#   ********
#   Now plot
#   Define plotting variables
y <- catch.df$forkLength
n <- catch.df$Unmarked  #catch.df$n
if( by.lifestage ){
#     lstage <- catch.df$lifeStageID
lstage <- catch.df$lifeStage
} else {
lstage <- rep(0, length(y))
}
#   Drop obs if any critical data is missing
#   If we are talking salmon here, limit the lifestages to fry, parr, and smolt
drop <-  is.na(y) | is.na(lstage) | is.na(n)
if( (length(taxon) == 1) & (taxon == 161980) & by.lifestage == TRUE ){   # jason add the by.lifetage condition.  only evaluate if lstage setup to vary
#     drop <- drop | (lstage > 8)
drop <- drop | !(lstage %in% c('Fry','Parr','Smolt'))
}
y <- y[!drop]
lstage <- lstage[!drop]
n <- n[!drop]
#   --------------------- Convert from lifestages the traps used to life stages that CAMP uses.  The conversion is in table rst.life.stages
# JASON OBSOLETE -- QUERY THAT GETS CATCH WORKS ON DESCRIPTORS INSTEAD OF IDS -- 1/26/2015
# if( by.lifestage ){
#     u.l.s <- sort(unique(lstage))
#     for( l.s in u.l.s ){
#         camp.l.s <- rst.life.stage$lifeStageCAMPID[ rst.life.stage$lifeStageID == l.s ]
#         lstage[ lstage == l.s ] <- camp.l.s
#     }
# }
#   -------------------- Rep the values for number of fish of that particular length
y <- rep(y, n)
lstage <- rep(lstage, n)
#   -------------------- An internal function to compute common break points
f.breaks<-function(x, near=10, width=2){
# x <- y
# near <- 10
# width <- 2
lolim <- trunc( min(x)/near ) * near   # rounds down to nearest 'near' number, eg., near = 5, rounds down to nearest multiple of 5
hilim <- ceiling( max(x)/near ) * near # rounds up to nearest 'near' number.
bks <- seq(lolim, hilim, by=width)
bks
}
#   -------------------- An internal function to compute common y axes
f.max.bar.hgt <- function(x, bks){
h <- hist(x, breaks=bks, plot=F )
max(h$counts)
}
#   -------------------- An internal function to draw one length frequency plot
f.len.freq<-function(x, bks, col, last=F, max.y, stage){
# x <- yy
# bks <- bks
# col <- mycol[ i ]
# last <- TRUE
# max.y <- max.y
# stage <- stage.name
#   Plot the bars
if(last) {
xa <- "s"
xl <- "Forklength (mm)"
} else {
xa <- "n"
xl <- ""
}
#   Uncomment the following line to plot everything on same y axis
#h <- hist(x, breaks=bks, freq=T, xlab=xl, ylab="", main="", ylim=c(0,max.y),
#    density=-1, col=col, xaxt=xa, cex.lab=2, cex.axis=1.25 )
h <- hist(x, breaks=bks, plot=F )  # get counts so can set ylim correctly
y.at <- pretty(h$counts)
#     h <- hist(x, breaks=bks, freq=T, xlab=xl, ylab="", main="", ylim=range(y.at),
#               density=-1, col=col, xaxt=xa, cex.lab=2, cex.axis=1.25, yaxt="n" )
# ----- jason update 12/16/2015 -------------------------------------------------------------------------------------------
h <- hist(x, breaks=bks, freq=T, xlab=xl, ylab="", main="", ylim=range(y.at),
density=-1, col=col, cex.lab=2, cex.axis=1.25, yaxt="n", xlim=range(bks), xaxt="n" )
if(last){     # last lifestage, so plot x-axis.
if((length(bks) %% 2) == 1){
bksL <- bks[c(TRUE,FALSE)]   # odd ticks
} else {
bksL <- c(bks[c(TRUE,FALSE)],bks[length(bks)])  # even ticks
}
axis( 1, at=bksL, labels=formatC(bksL, big.mark=","),cex.axis=0.85)
}
# ----- jason update 12/16/2015 -------------------------------------------------------------------------------------------
axis( 2, at=y.at, labels=formatC(y.at, big.mark=",") )
#   Smoothed density - If you want it
#require(MASS)
#pretty.bks <- pretty(bks)
#axis(side=1, at=pretty.bks )
#sm <- density( x, adjust=1.5, bw="SJ-dpi" )
#sm$y <- sm$y * (h$breaks[2] - h$breaks[1]) * sm$n
#lines( sm, col="black", lwd=2 )
#   Legend
n.str <- paste( "n (un-inflated)=", formatC(sum(h$counts), big.mark=",") )
top <- legend( "topright", legend=c(stage,n.str), plot=F, cex=2  )
text( max(bks), top$text$y[1], stage, cex=2, col=col, adj=1 )
text( max(bks), top$text$y[2], n.str, cex=1, col="black", adj=1 )
h
}
#   ---------------------- Set main titles
main.l1 <- attr(catch.df, "site.name")
main.l2 <- attr(catch.df, "species.name")
if( !is.na(attr(catch.df, "runID")) ){
main.l2 <- paste( main.l2, ", ", attr(catch.df, "run.name"), " run", sep="")
}
dts <- attr(catch.df, "run.season")
dts <- paste( format(dts$start, "%d%b%Y"), "to", format(dts$end, "%d%b%Y") )
main.l2 <- paste( main.l2, ", ", dts, sep="")
#   ---------------------- Plot by lifestage or not
if( by.lifestage ){
#   Plot by lifestage
life.stages <- sort(unique( lstage ))
if( length(life.stages) == 3 ){
mycol <- c("red", "orange", "blue")
} else {
mycol <- rainbow( length(life.stages) )
}
nl <- length(life.stages)
layout.mat <- rbind( c(nl+2,nl+2),
cbind( nl+1, 1:nl ))
layout.widths <- c(.075,.925)
layout.heights<- c(nl*.1, rep(1,nl-1), 1+nl*.1)
layout( layout.mat, widths=layout.widths, heights=layout.heights )
#layout.show(nl+2)
#   Get common breaks
bks <- f.breaks( y, 10, 2 )
#   Get max count overall lifestages in any one bin
max.y <- 0
for( i in 1:nl ){
ind <- life.stages[i] == lstage
yy <- y[ind]
max.y <- max( max.y, f.max.bar.hgt(yy, bks))
}
#   Plot histograms
for( i in 1:nl ){
ind <- life.stages[i] == lstage
yy <- y[ind]
stage.name <- CAMP.life.stage$lifeStageCAMP[ CAMP.life.stage$lifeStageCAMP == life.stages[i] ]
if( i == nl ){
# This is the bottom panel, make room for x-axis ticks and label
par(mar=c(5.1,2.1,.5,2.1))
} else {
par(mar=c(0,2.1,.5,2.1))
}
cnts <- f.len.freq(yy, bks, mycol[ i ], i == nl, max.y, stage.name)
if( i == 1 ){
ans <- data.frame( bin.mid.mm=cnts$mids, cnt=cnts$counts )
} else {
ans <- cbind( ans, cnt = cnts$counts )
}
names(ans)[ names(ans) == "cnt" ] <- paste0(casefold(stage.name), ".frequency")
}
#   Plot outer y axis label
par(mar=c(0,0,0,0))
plot(c(0,1), c(0,1), type="n", axes=F )
text( .5, .5, "Frequency", adj=.5, srt=90, cex=2 )
#   Plot outer title
str.hgt <- strheight(main.l1, units="user", cex=2)  * 1.2 / .1
plot(c(0,1), c(0,1), type="n", axes=F )
text( .5, 1 - str.hgt    ,  main.l1, adj=.5, cex=2 )
text( .5, 1 - 2.1*str.hgt,  main.l2, adj=.5, cex=1.5 )
text( .5, 1 - 2.9*str.hgt,     disc, adj=.5, cex=1.0)
} else {
#   ---- Plot only one histogram, much easier
bks <- f.breaks( y, 10, 2 )
cnts <- f.len.freq(y, bks, "orange", last=TRUE, max.y=f.max.bar.hgt(y, bks), stage="")
#   Main title
title( main=main.l1, line=3, cex.main=1.5)
title( main=main.l2, line=2, cex.main=1 )
title( main=disc   , line=1, cex.main=0.5)
title( main="All life stages", line=0, cex.main=.85)
#   Y label
title( ylab = "Frequency", cex.lab=2, line=2.5 )
#   Fix up the output
ans <- data.frame( bin.mid.mm=cnts$mids, frequency=cnts$counts )
}
#   ---- Close the graphics file
dev.off()
#   ---- Write the CSV file
out.csv <- paste(output.file, "_len_freq.csv", sep="")
write.table( ans, file=out.csv, sep=",", row.names=F )
#   ---- Send messages back to the interface
cat("SUCCESS - F.length.frequency\n\n")
cat(paste("Working directory:", getwd(), "\n"))
cat(paste("R data frames saved in file:", "<no RData saved>", "\n\n"))
cat("Number of files created in working directory = 2\n")
cat(paste(out.graphs, "\n"))
cat(paste(out.csv, "\n"))
cat("\n")
invisible(catch.df)
}
F.size.by.date    ( site, taxon, run, min.date, max.date,            output.file                                         )
F.length.frequency( site, taxon, run, min.date, max.date,     paste0(output.file,"_ls=F"),   by.lifestage=FALSE          )
F.length.frequency( site, taxon, run, min.date, max.date,     paste0(output.file,"_ls=T"),   by.lifestage=TRUE           )
# specify the range, in terms of theExcel rownames, to test.
for(testi in 1:75){
by <- 'All'
river <- as.character(droplevels(theExcel[testi,]$streamName))
if(river == ''){
db.file <- db.file1
} else if(river == 'Sacramento River'){
db.file <- db.file2
} else if(river == 'American River'){
db.file <- db.file3
} else if(river == ''){
db.file <- db.file4
} else if(river == 'Feather River'){
db.file <- db.file5
} else if(river == 'Stanislaus River'){
db.file <- db.file6
} else if(river == 'Old American Test'){
db.file <- db.file7
} else if(river == 'Mokelumne River'){
db.file <- db.file8
>>>>>>> origin/master
}
#   *****
#   Open ODBC channel
db <- get( "db.file", env=.GlobalEnv )
ch <- odbcConnectAccess(db)
#   *****
#   This SQL file develops the hours fished and TempSamplingSummary table
F.run.sqlFile( ch, "QrySamplePeriod.sql", R.TAXON=taxon )
#   *****
#   This SQL generates times when the traps were not fishing
F.run.sqlFile( ch, "QryNotFishing.sql" )
#   *****
#   This SQL generates unmarked fish by run and life stage
F.run.sqlFile( ch, "QryUnmarkedByRunLifestage.sql", R.TAXON=taxon )
#   Now, fetch the result
catch <- sqlFetch( ch, "TempSumUnmarkedByTrap_Run_Final" )
# add 3/8/2016 -- look for long gaps.
theLongCatches <- catch[catch$SampleMinutes > fishingGapMinutes,c('SampleDate','StartTime','EndTime','SampleMinutes','TrapStatus','siteID','siteName','trapPositionID','TrapPosition')]      # fishingGapMinutes set in source file -- it's global.
nLongCatches <- nrow(theLongCatches)
if(nLongCatches > 0){
warning("Long gaps were found in the data so the LongGapLoop series will be run.")
# SQL code to find the gaps, and modify trapPositionIDs accordingly.
F.run.sqlFile( ch, "QryFishingGaps.sql", R.FISHGAPMIN=fishingGapMinutes )
# get the updated results
catch2 <- sqlFetch( ch, "TempSumUnmarkedByTrap_Run_Final" )
catch <- catch2[catch2$SampleMinutes <= fishingGapMinutes,]   # this becomes the master catch df
} else {
# no long gaps to worry about.  so just keep going with the version of catch that we already
# pulled in from the mdb.
catch$oldtrapPositionID <- catch$trapPositionID    # these two are the same.  include for compatibility.
}
includecatchID <- sqlFetch(ch, "TempSamplingSummary")             # jason add to get variable includeCatchID
F.sql.error.check(catch)
close(ch)
if(nvisits > 0 & nrow(catch) == 0){
warning("Your criteria returned no catch records.  Check to make sure valid Fishing occurred within your date range.")
stop
}
#   ******************************************************************
#   Assign time zone (probably does not matter)
time.zone <- get( "time.zone", env=.GlobalEnv )
attr(catch$StartTime, "tzone") <- time.zone
attr(catch$EndTime, "tzone") <- time.zone
#  jason add all this get includeCatchID:  Assign time zone (definitely does matter -- otherwise it goes to MST)
time.zone <- get( "time.zone", env=.GlobalEnv )
# includecatchID$StartTime <- includecatchID$timeSampleStarted
includecatchID$EndTime <- includecatchID$timeSampleEnded
includecatchID$ProjID <- includecatchID$projectDescriptionID
includecatchID$timeSampleStarted <- includecatchID$timeSampleEnded <- includecatchID$projectDescriptionID <- includecatchID$trapVisitID <- includecatchID$sampleGearID <- NULL
# attr(includecatchID$StartTime, "tzone") <- time.zone
attr(includecatchID$EndTime, "tzone") <- time.zone
includecatchID <- includecatchID[,c('trapPositionID','EndTime','ProjID','includeCatchID')]
# sampleGearID ProjID trapPositionID trapVisitID
catch <- merge(catch,includecatchID,by=c('trapPositionID','EndTime','ProjID'),all.x=TRUE)
#   ********************************************************************
#   At this point, catch has all visits in it, even if no fish were caught.
#   It also has non-fishing intervals.  This is how you identify these intervals:
#       1. zero catch = catch$Unmarked == 0  ($FinalRun and $LifeStage are both "Unassigned" for these lines)
#       2. not fishing = catch$TrapStatus == "Not fishing"  (equivalently, $trapVisitID is missing for these lines.  Only time its missing.)
#
#   Pull apart the visits from the catch, because plus count expansion only applys to positive catches.
#   Recall, catch currently has multiple lines per trapVisit delineating fish with different fork lengths.
visit.ind <- !duplicated( catch$trapVisitID ) | (catch$TrapStatus == "Not fishing")
visits <- catch[visit.ind,!(names(catch) %in% c("Unmarked", "FinalRun", "lifeStage", "forkLength", "RandomSelection"))]
#   ********************************************************************
#   Subset the catches to just positives.  Toss the 0 catches and non-fishing visits.
catch <- catch[ (catch$Unmarked > 0) & (catch$TrapStatus == "Fishing"), ]
# get summary counts of catch run vs. lifetstage for internal checking.
totalFish <<- sum(catch$Unmarked)
# jason adds the if here 1/12/2016, since for some reports, we could have 0 valid catch, but non-zero invalid catch.
# aggregate doesn't work on zero rows, thus requiring the if-clause.
if(nrow(catch) > 0){
totalRun <<- aggregate(catch$Unmarked, list(FinalRun=catch$FinalRun), FUN=sum)
totalLifeStage <<- aggregate(catch$Unmarked, list(LifeStage=catch$lifeStage), FUN=sum)
totalRunXLifeStage <<- aggregate(catch$Unmarked, list(LifeStage=catch$lifeStage,FinalRun=catch$FinalRun), FUN=sum)
}
catch$Unassd <- catch$lifeStage # jason add to ID the unassigned lifeStage -- necessary to separate measured vs caught.
#   ********************************************************************
catchSave <<- catch
nHalfCone <- nrow(catch[catch$halfConeID == 1,])
if(nHalfCone > 0){   # do a different plus-count algorithm in this case.  1/14/2016.
preCatch <- catch
# expand half-cone operations to full-cone.  this needs to happen prior to plus-counting.
catch$preUnmarked <- catch$Unmarked
catch$Unmarked <- ifelse(catch$halfConeID == 1,halfConeMulti*catch$preUnmarked,catch$preUnmarked)
catch$preUnmarked <- NULL    # served its purpose -- also, plus-counting duplicates these numbers
#   Expand the Plus counts
preCatch2 <- F.expand.plus.counts( preCatch )
catch2 <- F.expand.plus.counts( catch )
names(preCatch2)[names(preCatch2) == 'Unmarked'] <- 'preUnmarked'    # now, put this variable back to preUnmarked, to prepare for merge
test <- merge(catch2,preCatch2[,c('trapVisitID','FinalRun','lifeStage','forkLength','RandomSelection','Unassd','preUnmarked')],by=c('trapVisitID','FinalRun','lifeStage','forkLength','RandomSelection','Unassd'),all.x=TRUE)
possiblyOff <- test[is.na(test$preUnmarked),]   # possible trouble spots
test$preUnmarked[is.na(test$preUnmarked)] <- 0   # unassigned fish that were not assigned to a certain category before, but were after -or- fish that were assigned a diff lifestage and finalrun between preCatch and catch
test$halfConeAssignedCatch   <- ifelse(test$halfConeID == 1 & test$Unassd != 'Unassigned',test$Unmarked - test$preUnmarked,0)    # halfConeAdj have to originate from a halfCone trapping instance.
test$halfConeUnassignedCatch <- ifelse(test$halfConeID == 1 & test$Unassd == 'Unassigned',test$Unmarked - test$preUnmarked,0)    # halfConeAdj have to originate from a halfCone trapping instance.
test$assignedCatch   <- ifelse(test$Unassd != 'Unassigned',test$Unmarked - test$halfConeAssignedCatch,0)
test$unassignedCatch <- ifelse(test$Unassd == 'Unassigned',test$Unmarked - test$halfConeUnassignedCatch,0)
# deal with awkwardness of doing the plus-count routine two times with slightly different data (due to plus-counting)
#                                    ,after 'times2' - before 'times2'
test$off <- ifelse(test$halfConeID==2,test$Unmarked - test$preUnmarked,test$Unmarked - test$halfConeAssignedCatch - test$halfConeUnassignedCatch - test$preUnmarked)
#                                    , should be zero
test$preUnmarked <- ifelse(test$halfConeID == 2 & test$off != 0,test$Unmarked,test$preUnmarked)
test$off2 <- ifelse(test$halfConeID==2,test$Unmarked - test$preUnmarked,test$Unmarked - test$halfConeAssignedCatch - test$halfConeUnassignedCatch - test$preUnmarked)
#   look <- test[,c('trapVisitID','FinalRun','lifeStage','forkLength','RandomSelection','Unassd','trapPositionID','SampleDate','TrapStatus','TrapPosition','halfConeID','Unmarked','preUnmarked','halfConeAssignedCatch','halfConeUnassignedCatch','assignedCatch','unassignedCatch')]
#   look[as.Date(look$SampleDate) == '2014-02-28' & look$TrapPosition == 'Gate 8',]
test$modUnassignedCatch <- test$halfConeUnassignedCatch + test$unassignedCatch
test$modAssignedCatch <- test$halfConeAssignedCatch + test$assignedCatch
test$off <- test$off2 <- NULL
catch <- test
} else {
# data query where all are full catch -- just set the fancy variables to zero.
catch <- F.expand.plus.counts( catch )
catch$preUnmarked <- catch$Unmarked
if(nrow(catch) > 0){catch$halfConeAssignedCatch <- 0}
if(nrow(catch) > 0){catch$halfConeUnassignedCatch <- 0}
catch$assignedCatch   <- ifelse(catch$Unassd != 'Unassigned',catch$Unmarked - catch$halfConeAssignedCatch,0)
catch$unassignedCatch <- ifelse(catch$Unassd == 'Unassigned',catch$Unmarked - catch$halfConeUnassignedCatch,0)
catch$modUnassignedCatch <- catch$halfConeUnassignedCatch + catch$unassignedCatch
catch$modAssignedCatch <- catch$halfConeAssignedCatch + catch$assignedCatch
}
#   Reassign factor levels because they may have changed.  I.e., we may have eliminated "Unassigned"
catch$FinalRun <- as.character( catch$FinalRun )
catch$lifeStage <- as.character( catch$lifeStage )
#catch$lifeStage <- as.character( catch$Unassd ) jason - possibly delete
#   ********************************************************************
#   Assign batch dates -- jason adds the ifs 1/16/2016 to allow zero row visits and catch dfs to pass through
if(nrow(visits) > 0){visits <- F.assign.batch.date( visits )}
if(nrow(catch) > 0){catch <- F.assign.batch.date( catch )}
#   Assign attributes
attr(catch, "siteID" ) <- site
attr(catch, "site.name") <- catch$siteName[1]
#attr(catch, "site.abbr") <- catch$siteAbbreviation[1]
#attr(catch, "runID") <- run
#attr(catch, "run.name") <- run.name
#attr(catch, "run.season") <- run.season
#attr(catch, "site.stream") <- site.stream
attr(catch, "subsites") <- unique(catch$trapPositionID)
#attr(catch, "taxonID" ) <- taxon.string
#attr(catch, "species.name") <- sp.commonName
#
cat("First 20 records of catch data frame...\n")
if( nrow(catch) >= 20 ) print( catch[1:20,] ) else print( catch )
#f.banner("F.get.catch.data - Complete")
#   Return two data frames. One containing positive catches.  The other containing visit and fishing information.
list( catch=catch, visit=visits )
}
F.length.frequency( site, taxon, run, min.date, max.date,     paste0(output.file,"_ls=F"),   by.lifestage=FALSE          )
F.length.frequency( site, taxon, run, min.date, max.date,     paste0(output.file,"_ls=T"),   by.lifestage=TRUE           )
<<<<<<< HEAD
dev.off()
dev.off()
dev.off()
dev.off()
dev.off()
F.size.by.date    ( site, taxon, run, min.date, max.date,            output.file                                         )
=======
#F.release.summary ( site, taxon, run, min.date, max.date,            output.file                                         )
#F.weekly.effort   ( site, taxon,      min.date, max.date,            output.file                                         )
}
testi
>>>>>>> origin/master
